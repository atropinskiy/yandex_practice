{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Иморт-бибилиотек\" data-toc-modified-id=\"Иморт-бибилиотек-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Иморт бибилиотек</a></span></li><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Загрузка данных</a></span></li><li><span><a href=\"#Обработка-текста-и-деление\" data-toc-modified-id=\"Обработка-текста-и-деление-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Обработка текста и деление</a></span><ul class=\"toc-item\"><li><span><a href=\"#Деление-на-тренировочную-и-тестовую-выборки\" data-toc-modified-id=\"Деление-на-тренировочную-и-тестовую-выборки-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Деление на тренировочную и тестовую выборки</a></span></li></ul></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Random-forest\" data-toc-modified-id=\"Random-forest-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>Random forest</a></span></li><li><span><a href=\"#Logistic-regression\" data-toc-modified-id=\"Logistic-regression-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>Logistic regression</a></span></li><li><span><a href=\"#Catboost\" data-toc-modified-id=\"Catboost-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span>Catboost</a></span></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-2.0.4\"><span class=\"toc-item-num\">2.0.4&nbsp;&nbsp;</span>Тестирование</a></span></li></ul></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка\n",
    "### Иморт бибилиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('./datasets/toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текст на английском, поэтому будем исопльзовать обычный BERT.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Типы данных в порядке. В датасете около 160 тыс. фраз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.000000</td>\n",
       "      <td>159292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79725.697242</td>\n",
       "      <td>0.101612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46028.837471</td>\n",
       "      <td>0.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39872.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79721.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>119573.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159450.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0          toxic\n",
       "count  159292.000000  159292.000000\n",
       "mean    79725.697242       0.101612\n",
       "std     46028.837471       0.302139\n",
       "min         0.000000       0.000000\n",
       "25%     39872.750000       0.000000\n",
       "50%     79721.500000       0.000000\n",
       "75%    119573.250000       0.000000\n",
       "max    159450.000000       1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевой столбец - булевый, что нам и требовалось.\n",
    "Доля токсичных комментариев - чуть больше 10%  \n",
    "Не понятно, что за столбец unnamed, похоже на дублирование индекса, проверим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все верно, это дубликат, удалим его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['text','toxic']]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшим датафрейм до 30000. При необходимости увеличим позже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1011375"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(80000,random_state=12345)\n",
    "df['toxic'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка текста и деление"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Деление на тренировочную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.sample(frac=0.8, random_state=42)\n",
    "test = df.drop(train.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\atropinskiy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords = set(nltk_stopwords.words('english'))\n",
    "stopwords = 'english'\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>formatted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156947</th>\n",
       "      <td>Check Out Mentone Grammar School's talk page\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>check out mentone grammar schools talk page  i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95179</th>\n",
       "      <td>I agree with  and  that reference to the longe...</td>\n",
       "      <td>0</td>\n",
       "      <td>i agree with  and  that reference to the longe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54035</th>\n",
       "      <td>Julie Greene &lt;3 \\n\\nTeddy Barrett.\\nIs Trouble...</td>\n",
       "      <td>0</td>\n",
       "      <td>julie greene    teddy barrett is trouble and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75962</th>\n",
       "      <td>\"\\nI agree. A simple map of the area would suf...</td>\n",
       "      <td>0</td>\n",
       "      <td>i agree a simple map of the area would suffice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63634</th>\n",
       "      <td>Contested deletion \\n\\nThis article should not...</td>\n",
       "      <td>0</td>\n",
       "      <td>contested deletion   this article should not b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "156947  Check Out Mentone Grammar School's talk page\\n...      0   \n",
       "95179   I agree with  and  that reference to the longe...      0   \n",
       "54035   Julie Greene <3 \\n\\nTeddy Barrett.\\nIs Trouble...      0   \n",
       "75962   \"\\nI agree. A simple map of the area would suf...      0   \n",
       "63634   Contested deletion \\n\\nThis article should not...      0   \n",
       "\n",
       "                                           formatted_text  \n",
       "156947  check out mentone grammar schools talk page  i...  \n",
       "95179   i agree with  and  that reference to the longe...  \n",
       "54035   julie greene    teddy barrett is trouble and i...  \n",
       "75962   i agree a simple map of the area would suffice...  \n",
       "63634   contested deletion   this article should not b...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning(text):\n",
    "    text = re.sub(r\"(?:\\n|\\r)\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z ]+\", \"\", text).strip()\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "train['formatted_text'] = train['text'].apply(cleaning)\n",
    "test['formatted_text'] = test['text'].apply(cleaning)\n",
    "\n",
    "y_train = train['toxic']\n",
    "y_test = test['toxic']\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = count_tf_idf.fit_transform(train['formatted_text'])\n",
    "tfidf_test = count_tf_idf.transform(test['formatted_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best parameters is: {'max_depth': 5, 'max_features': 10000, 'n_estimators': 13}\n",
      "Best score for RF is: 0.23370604548252846\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "params_rf = {\n",
    "    'n_estimators': [13],\n",
    "    'max_depth':[5],\n",
    "    'max_features' : [10000]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model_rf, param_grid=params_rf, scoring='f1', cv=3, verbose=True, n_jobs=-1)\n",
    "\n",
    "best_grid = grid.fit(tfidf_train, y_train)\n",
    "print('Best parameters is:', grid.best_params_)\n",
    "print('Best score for RF is:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters is: {'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best score for RF is: 0.7344290297341093\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression()\n",
    "\n",
    "parameters_lr = {\n",
    "    'penalty' : ['l1','l2'], \n",
    "    'solver'  : ['lbfgs', 'liblinear'],\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(model_lr,                    \n",
    "                   param_grid = parameters_lr,  \n",
    "                   scoring='f1',\n",
    "                   cv=3)\n",
    "grid_lr.fit(tfidf_train, y_train)\n",
    "\n",
    "print('Best parameters is:', grid_lr.best_params_)\n",
    "print('Best score for RF is:', grid_lr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кэтбуст умеет самостоятельно векторизировать текст, поэтому оставим ему только обработанный текст в качестве признаков.\n",
    "X_train = train.drop(['toxic', 'text'],axis=1)\n",
    "X_test = test.drop(['toxic', 'text'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший результат: 0.7565341719897716\n",
      "Лучшие параметры: {'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "catboost = CatBoostClassifier(logging_level = 'Silent',\n",
    "                              text_features=['formatted_text'])\n",
    "\n",
    "parameters_cb = {'learning_rate': [0.1], # Оставил лучшие параметры для экономии времени\n",
    "                'l2_leaf_reg': [1],\n",
    "                'iterations' : [500]}\n",
    "\n",
    "grid_cb  = GridSearchCV(estimator=catboost, \n",
    "                     param_grid = parameters_cb, \n",
    "                     cv = 2, \n",
    "                     n_jobs=-1,\n",
    "                     scoring='f1')\n",
    "\n",
    "grid_cb.fit(X_train, y_train)\n",
    "\n",
    "print ('Лучший результат:', grid_cb.best_score_)\n",
    "print ('Лучшие параметры:', grid_cb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1 score for CB is: 0.7710184552289817\n",
      "Best f1 score for LR is: 0.7401978746793697\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_pred = grid_cb.predict(X_test)\n",
    "print ('Best f1 score for CB is:',f1_score(y_test, test_pred))\n",
    "test_pred = grid_lr.predict(tfidf_test)\n",
    "print ('Best f1 score for LR is:',f1_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. В данном проекте мы преобразовали текст, токенизировали его, удалили стоп-слов, что позволило нам построить несколько моделей.\n",
    "2. Изначально мы уменьшили количество данных до 80000, чтобы сэкономить ресурсы\n",
    "3. Лучше всех отработал Catboost, стоит отметить, что для построения модели с определенными гиперпараметрами ему хватило и 30тыс. данных, что является отличным результатом. И это позволило ему превысить порог 75% в f1, что и требовалось в проекте.\n",
    "4. Также неплохо отработала Логическая регрессия, но с учетом кроссвалидации на тестовой выборке она не дала нужного результата\n",
    "5. Модель RF отработала хуже. всех.\n",
    "\n",
    "В результате предлагаю использовать модель catboost, которая показала лучший результат по точности, также у нас остается резерв на улучшение качества модели, не урезая до 80000 начальный датафрейм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 53,
    "start_time": "2023-03-28T10:55:49.528Z"
   },
   {
    "duration": 1871,
    "start_time": "2023-03-28T10:55:55.071Z"
   },
   {
    "duration": 2388,
    "start_time": "2023-03-28T10:55:56.944Z"
   },
   {
    "duration": 34,
    "start_time": "2023-03-28T10:55:59.334Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-28T10:55:59.382Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-28T10:55:59.415Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-28T10:55:59.433Z"
   },
   {
    "duration": 78,
    "start_time": "2023-03-28T10:55:59.448Z"
   },
   {
    "duration": 158,
    "start_time": "2023-03-28T10:55:59.528Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-28T10:55:59.688Z"
   },
   {
    "duration": 2736,
    "start_time": "2023-03-28T10:55:59.695Z"
   },
   {
    "duration": 1326,
    "start_time": "2023-03-28T10:56:02.433Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-28T10:56:03.761Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-28T10:56:03.762Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-28T10:56:03.764Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-28T10:56:03.765Z"
   },
   {
    "duration": 2531,
    "start_time": "2023-03-28T10:56:20.522Z"
   },
   {
    "duration": 7080,
    "start_time": "2023-03-28T10:57:07.485Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-28T11:08:36.562Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-28T11:09:14.933Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-28T11:09:21.323Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-28T11:10:39.264Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-28T11:10:50.270Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-28T11:11:34.593Z"
   },
   {
    "duration": 50,
    "start_time": "2023-03-29T09:49:02.700Z"
   },
   {
    "duration": 2758,
    "start_time": "2023-03-29T09:49:08.300Z"
   },
   {
    "duration": 2173,
    "start_time": "2023-03-29T09:49:11.060Z"
   },
   {
    "duration": 32,
    "start_time": "2023-03-29T09:49:13.235Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-29T09:49:13.269Z"
   },
   {
    "duration": 26,
    "start_time": "2023-03-29T09:49:13.302Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-29T09:49:13.330Z"
   },
   {
    "duration": 80,
    "start_time": "2023-03-29T09:49:13.360Z"
   },
   {
    "duration": 158,
    "start_time": "2023-03-29T09:49:13.441Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-29T09:49:13.601Z"
   },
   {
    "duration": 2667,
    "start_time": "2023-03-29T09:49:13.607Z"
   },
   {
    "duration": 7441,
    "start_time": "2023-03-29T09:49:16.276Z"
   },
   {
    "duration": 60636,
    "start_time": "2023-03-29T09:49:23.719Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-29T09:50:24.358Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
